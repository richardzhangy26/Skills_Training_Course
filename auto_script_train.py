import requests
import json
import time
import os
import difflib
from datetime import datetime
from pathlib import Path
from openai import OpenAI
from typing import Optional, List, Dict
from workflow_tester_base import WorkflowTesterBase


class DialogueEntry:
    """å¯¹è¯æ—¥å¿—æ¡ç›®"""
    def __init__(self, timestamp: str, step_id: str, source: str,
                 ai_text: Optional[str] = None, user_text: Optional[str] = None,
                 round_num: Optional[int] = None):
        self.timestamp = timestamp
        self.step_id = step_id
        self.source = source  # "runCard" æˆ– "chat"
        self.ai_text = ai_text
        self.user_text = user_text
        self.round_num = round_num

    def __repr__(self):
        return f"DialogueEntry(timestamp={self.timestamp}, step_id={self.step_id}, " \
               f"source={self.source}, round={self.round_num})"


class DialogueLogParser:
    """å¯¹è¯æ—¥å¿—è§£æå™¨"""

    @staticmethod
    def parse_log_file(log_path: str) -> List[DialogueEntry]:
        """
        è§£æå¯¹è¯æ—¥å¿—æ–‡ä»¶

        Args:
            log_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„

        Returns:
            è§£æåçš„å¯¹è¯æ¡ç›®åˆ—è¡¨
        """
        entries = []

        try:
            with open(log_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
            return entries

        # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²å¯¹è¯å—ï¼ˆå¤„ç†å¯èƒ½çš„æ¢è¡Œç¬¦å·®å¼‚ï¼‰
        separator = '-' * 80
        # æ›¿æ¢æ‰€æœ‰å¯èƒ½çš„åˆ†éš”ç¬¦å˜ä½“ä¸ºç»Ÿä¸€æ ¼å¼
        normalized_content = content.replace(separator + '\r\n', separator + '\n')
        normalized_content = normalized_content.replace(separator + '\r', separator + '\n')
        blocks = normalized_content.split(separator + '\n')

        for block in blocks:
            if not block.strip():
                continue

            entry = DialogueLogParser._parse_block(block)
            if entry:
                entries.append(entry)

        print(f"âœ… è§£ææ—¥å¿—æ–‡ä»¶å®Œæˆï¼Œå…± {len(entries)} ä¸ªå¯¹è¯æ¡ç›®")
        return entries

    @staticmethod
    def _parse_block(block: str) -> Optional[DialogueEntry]:
        """è§£æå•ä¸ªå¯¹è¯å—"""
        lines = block.strip().split('\n')
        if not lines:
            return None

        # è§£æå¤´éƒ¨ä¿¡æ¯
        header = lines[0]
        timestamp, step_id, round_num, source = DialogueLogParser._parse_header(header)

        # è§£æç”¨æˆ·å’ŒAIæ–‡æœ¬
        ai_text = None
        user_text = None

        for line in lines[1:]:
            line = line.strip()
            if line.startswith('AI:'):
                ai_text = line[3:].strip()
            elif line.startswith('ç”¨æˆ·:'):
                user_text = line[3:].strip()

        return DialogueEntry(
            timestamp=timestamp,
            step_id=step_id,
            source=source,
            ai_text=ai_text,
            user_text=user_text,
            round_num=round_num
        )

    @staticmethod
    def _parse_header(header: str) -> tuple:
        """è§£æå¤´éƒ¨ä¿¡æ¯"""
        # ç¤ºä¾‹: [2025-11-28 16:01:21] Step GnxX4RzREzTrXNmRGxq0 | ç¬¬ 1 è½® | æ¥æº: chat
        timestamp = ""
        step_id = ""
        round_num = None
        source = "chat"

        try:
            # æå–æ—¶é—´æˆ³
            if header.startswith('['):
                end_idx = header.find(']')
                if end_idx > 0:
                    timestamp = header[1:end_idx].strip()

            # æå–æ­¥éª¤ID
            step_start = header.find('Step ')
            if step_start > 0:
                step_end = header.find(' |', step_start)
                if step_end > 0:
                    step_id = header[step_start + 5:step_end].strip()

            # æå–è½®æ¬¡
            round_start = header.find('ç¬¬ ')
            if round_start > 0:
                round_end = header.find(' è½®', round_start)
                if round_end > 0:
                    round_str = header[round_start + 2:round_end].strip()
                    try:
                        round_num = int(round_str)
                    except ValueError:
                        round_num = None

            # æå–æ¥æº
            source_start = header.find('æ¥æº: ')
            if source_start > 0:
                source = header[source_start + 4:].strip()
        except Exception as e:
            print(f"âš ï¸  è§£æå¤´éƒ¨ä¿¡æ¯å¤±è´¥: {header}, é”™è¯¯: {str(e)}")

        return timestamp, step_id, round_num, source

    @staticmethod
    def extract_dialogue_pairs(entries: List[DialogueEntry]) -> List[Dict]:
        """
        ä»å¯¹è¯æ¡ç›®ä¸­æå–AIæé—®-ç”¨æˆ·å›ç­”å¯¹

        Args:
            entries: å¯¹è¯æ¡ç›®åˆ—è¡¨

        Returns:
            [{"ai": ai_text, "user": user_text}, ...]
        """
        pairs = []

        for entry in entries:
            if entry.source == "chat" and entry.ai_text and entry.user_text:
                pairs.append({
                    "ai": entry.ai_text,
                    "user": entry.user_text,
                    "timestamp": entry.timestamp,
                    "step_id": entry.step_id,
                    "round_num": entry.round_num
                })

        print(f"âœ… æå–åˆ° {len(pairs)} ä¸ªå¯¹è¯å¯¹")
        return pairs


class DialogueMatcher:
    """å¯¹è¯åŒ¹é…å™¨"""

    def __init__(self, similarity_threshold: float = 0.7):
        """
        åˆå§‹åŒ–åŒ¹é…å™¨

        Args:
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.7
        """
        self.threshold = similarity_threshold

    def find_best_match(self, ai_question: str, dialogue_pairs: List[Dict]) -> Optional[str]:
        """
        æŸ¥æ‰¾æœ€ä½³åŒ¹é…çš„ç”¨æˆ·å›ç­”

        Args:
            ai_question: å½“å‰AIæé—®
            dialogue_pairs: å†å²å¯¹è¯å¯¹åˆ—è¡¨

        Returns:
            åŒ¹é…çš„ç”¨æˆ·å›ç­”ï¼Œæˆ–Noneè¡¨ç¤ºæœªæ‰¾åˆ°
        """
        if not dialogue_pairs:
            return None

        best_match = None
        best_similarity = 0.0
        best_pair_info = None

        for pair in dialogue_pairs:
            historical_ai = pair.get("ai", "")
            if not historical_ai:
                continue

            similarity = self.calculate_similarity(ai_question, historical_ai)

            if similarity > best_similarity and similarity >= self.threshold:
                best_similarity = similarity
                best_match = pair.get("user")
                best_pair_info = {
                    "similarity": similarity,
                    "historical_ai": historical_ai,
                    "timestamp": pair.get("timestamp"),
                    "step_id": pair.get("step_id"),
                    "round_num": pair.get("round_num")
                }

        if best_match:
            print(f"âœ… æ‰¾åˆ°åŒ¹é…å›ç­”ï¼Œç›¸ä¼¼åº¦: {best_similarity:.2f}")
            if best_pair_info:
                print(f"   åŸå§‹AIæé—®: {best_pair_info['historical_ai'][:50]}...")
                print(f"   æ—¶é—´: {best_pair_info.get('timestamp')}, æ­¥éª¤: {best_pair_info.get('step_id')}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…å›ç­” (æœ€é«˜ç›¸ä¼¼åº¦: {best_similarity:.2f}, é˜ˆå€¼: {self.threshold})")

        return best_match

    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦

        Args:
            text1: æ–‡æœ¬1
            text2: æ–‡æœ¬2

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0.0-1.0)
        """
        if not text1 or not text2:
            return 0.0

        # é¢„å¤„ç†ï¼šå»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œç¬¦
        text1_clean = ' '.join(text1.split())
        text2_clean = ' '.join(text2.split())

        # ä½¿ç”¨difflibè®¡ç®—ç›¸ä¼¼åº¦
        return difflib.SequenceMatcher(None, text1_clean, text2_clean).ratio()


class DialogueReplayEngine:
    """å¯¹è¯å›æ”¾å¼•æ“"""

    def __init__(self, log_path: str, similarity_threshold: float = 0.7):
        """
        åˆå§‹åŒ–å›æ”¾å¼•æ“

        Args:
            log_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.log_path = log_path
        self.threshold = similarity_threshold
        self.parser = DialogueLogParser()
        self.matcher = DialogueMatcher(similarity_threshold)
        self.dialogue_pairs = None
        self.loaded = False

    def load_log(self) -> bool:
        """åŠ è½½å’Œè§£ææ—¥å¿—æ–‡ä»¶"""
        try:
            entries = self.parser.parse_log_file(self.log_path)
            self.dialogue_pairs = self.parser.extract_dialogue_pairs(entries)
            self.loaded = True
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½æ—¥å¿—å¤±è´¥: {str(e)}")
            return False

    def get_answer(self, ai_question: str) -> Optional[str]:
        """
        è·å–åŒ¹é…çš„å›ç­”

        Args:
            ai_question: AIæé—®

        Returns:
            åŒ¹é…çš„ç”¨æˆ·å›ç­”ï¼Œæˆ–Noneè¡¨ç¤ºæœªæ‰¾åˆ°
        """
        if not self.loaded or not self.dialogue_pairs:
            print("âš ï¸  æ—¥å¿—æœªåŠ è½½æˆ–ä¸ºç©º")
            return None

        return self.matcher.find_best_match(ai_question, self.dialogue_pairs)

    def get_match_info(self, ai_question: str) -> Dict:
        """
        è·å–åŒ¹é…çš„è¯¦ç»†ä¿¡æ¯

        Args:
            ai_question: AIæé—®

        Returns:
            åŒ¹é…ä¿¡æ¯å­—å…¸
        """
        if not self.loaded or not self.dialogue_pairs:
            return {"error": "æ—¥å¿—æœªåŠ è½½æˆ–ä¸ºç©º"}

        best_match = None
        best_similarity = 0.0
        best_pair = None

        for pair in self.dialogue_pairs:
            historical_ai = pair.get("ai", "")
            if not historical_ai:
                continue

            similarity = self.matcher.calculate_similarity(ai_question, historical_ai)

            if similarity > best_similarity:
                best_similarity = similarity
                best_match = pair.get("user")
                best_pair = pair

        return {
            "matched": best_similarity >= self.threshold,
            "similarity": best_similarity,
            "answer": best_match,
            "threshold": self.threshold,
            "historical_ai": best_pair.get("ai") if best_pair else None,
            "timestamp": best_pair.get("timestamp") if best_pair else None,
            "step_id": best_pair.get("step_id") if best_pair else None,
            "round_num": best_pair.get("round_num") if best_pair else None,
            "total_pairs": len(self.dialogue_pairs)
        }


class WorkflowTester(WorkflowTesterBase):
    DEFAULT_PROFILE_KEY = "medium"
    PROFILE_LABEL_FIELD_NAME = "å­¦ç”Ÿæ¡£ä½"
    PROFILE_SELECT_TITLE = "å­¦ç”Ÿæ¡£ä½"

    STUDENT_PROFILES = {
        "good": {
            "label": "ä¼˜ç§€å­¦ç”Ÿ",
            "description": "ç†è§£é€å½»ã€è¡¨è¾¾æ¸…æ™°ï¼Œå›ç­”ç»“æ„åŒ–ã€æ¡ç†åˆ†æ˜ï¼Œå¹¶ä¸»åŠ¨æ€»ç»“è¦ç‚¹ã€‚",
            "style": "è¯­æ°”è‡ªä¿¡ã€è¯­è¨€è§„èŒƒï¼Œå¿…è¦æ—¶å¼•ç”¨é¢˜ç›®æˆ–ææ–™ä¸­çš„å…³é”®ä¿¡æ¯ã€‚",
            "fallback_hint": "è‹¥æ¨¡æ‹Ÿå¯¹è¯ä¸­æ²¡æœ‰åˆé€‚ç¤ºä¾‹ï¼Œå¯è‡ªå·±ç»„ç»‡æœ€ä½³ç­”æ¡ˆï¼Œä¿æŒé«˜æ°´å¹³ã€‚"
        },
        "medium": {
            "label": "éœ€è¦å¼•å¯¼çš„å­¦ç”Ÿ",
            "description": "åŸºæœ¬ç†è§£é—®é¢˜ä½†ä¸å¤Ÿå…¨é¢ï¼Œå›ç­”ä¸­ä¼šæš´éœ²ç–‘æƒ‘æˆ–è¯·æ±‚æç¤ºã€‚",
            "style": "è¯­æ°”ç•¥æ˜¾çŠ¹è±«ï¼Œèƒ½è¦†ç›–æ ¸å¿ƒå†…å®¹ï¼Œä½†ä¼šæå‡º 1-2 ä¸ªä¸ç¡®å®šç‚¹æˆ–å¯»æ±‚è€å¸ˆå»ºè®®ã€‚",
            "fallback_hint": "ç¤ºä¾‹ç¼ºå¤±æ—¶ï¼Œå…ˆå›ç­”ä¸»è¦å†…å®¹å†è¯´æ˜ä¸ç¡®å®šä¹‹å¤„ã€‚"
        },
        "bad": {
            "label": "ç­”éæ‰€é—®çš„å­¦ç”Ÿ",
            "description": "ç†è§£åå·®ï¼Œå¸¸å¸¸è·‘é¢˜æˆ–åªå¤è¿°ä¸é—®é¢˜å¼±ç›¸å…³çš„ä¿¡æ¯ã€‚",
            "style": "è¯­æ°”éšæ„ï¼Œå®¹æ˜“åç¦»é‡ç‚¹æˆ–ç­”éæ‰€é—®ã€‚",
            "fallback_hint": "å³ä½¿éœ€è¦è‡ªå·±ç”Ÿæˆï¼Œä¹Ÿè¦ä¿æŒè½»å¾®è·‘é¢˜æˆ–è¯¯è§£çš„ç‰¹å¾ã€‚"
        }
    }

    def __init__(self, base_url="https://cloudapi.polymas.com"):
        super().__init__(base_url)

        # Provide profile data for base prompt/selection helpers.
        self.student_profiles = self.STUDENT_PROFILES

        # é‡è¯•é…ç½®
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.base_timeout = 60  # åŸºç¡€è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.retry_backoff = 2  # é‡è¯•é€€é¿å› å­

        # åˆå§‹åŒ– Doubao å®¢æˆ·ç«¯
        self.doubao_client = None
        self.doubao_model = os.getenv("DOUBAO_MODEL", "doubao-seed-1-6-251015")

        # å›æ”¾æ¨¡å¼ç›¸å…³å±æ€§
        self.replay_engine = None
        self.use_replay_mode = False
        self.similarity_threshold = 0.7
        self.replay_log_path = None

        self._initialize_doubao_client()

    def _initialize_doubao_client(self):
        """åˆå§‹åŒ– Doubao å®¢æˆ·ç«¯"""
        api_key = os.getenv("ARK_API_KEY")
        base_url = os.getenv("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")

        if api_key:
            try:
                self.doubao_client = OpenAI(api_key=api_key, base_url=base_url)
            except Exception as e:
                print(f"âš ï¸  è­¦å‘Š: åˆå§‹åŒ– Doubao å®¢æˆ·ç«¯å¤±è´¥: {str(e)}")

    def _retry_request(self, request_func, *args, **kwargs):
        """
        é€šç”¨é‡è¯•æœºåˆ¶

        Args:
            request_func: è¦æ‰§è¡Œçš„è¯·æ±‚å‡½æ•°
            *args, **kwargs: ä¼ é€’ç»™è¯·æ±‚å‡½æ•°çš„å‚æ•°

        Returns:
            è¯·æ±‚ç»“æœ
        """
        last_exception = None

        for attempt in range(self.max_retries):
            try:
                # åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´
                timeout = self.base_timeout * (attempt + 1)
                if 'timeout' in kwargs:
                    kwargs['timeout'] = timeout

                print(f"ğŸ”„ å°è¯•ç¬¬ {attempt + 1}/{self.max_retries} æ¬¡è¯·æ±‚ (è¶…æ—¶: {timeout}ç§’)...")

                result = request_func(*args, **kwargs)

                # å¦‚æœæˆåŠŸï¼Œè¿”å›ç»“æœ
                if attempt > 0:
                    print(f"âœ… é‡è¯•æˆåŠŸï¼")
                return result

            except requests.exceptions.ReadTimeout as e:
                last_exception = e
                print(f"âš ï¸  è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.max_retries})")

                if attempt < self.max_retries - 1:
                    # è®¡ç®—é€€é¿ç­‰å¾…æ—¶é—´
                    wait_time = self.retry_backoff ** attempt
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")

            except requests.exceptions.RequestException as e:
                # å…¶ä»–ç½‘ç»œé”™è¯¯ï¼Œä¸é‡è¯•
                print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
                raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise Exception(f"è¯·æ±‚è¶…æ—¶ï¼Œå·²é‡è¯• {self.max_retries} æ¬¡")

    def _post_json(self, url: str, payload: Dict, timeout: int):
        """Override base POST to add retries."""
        def make_request():
            return self.session.post(
                url,
                json=payload,
                headers=self.headers,
                timeout=timeout,
            )
        return self._retry_request(make_request)

    def _log_run_card(self, step_id, payload, response_data):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_lines = [
            f"[{timestamp}] Step {step_id}",
            f"è¯·æ±‚è½½è·: {json.dumps(payload, ensure_ascii=False)}",
            f"å“åº”å†…å®¹: {json.dumps(response_data, ensure_ascii=False)}",
            "-" * 80,
        ]
        self._append_log(self.run_card_log_path, "\n".join(log_lines))

    def _log_dialogue_entry(self, step_id, user_text=None, ai_text=None, source="chat"):
        if user_text is None and ai_text is None:
            return
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        round_info = f" | ç¬¬ {self.dialogue_round} è½®" if self.dialogue_round else ""
        header = f"[{timestamp}] Step {step_id}{round_info} | æ¥æº: {source}"
        lines = [header]
        if user_text:
            lines.append(f"ç”¨æˆ·: {user_text}")
        if ai_text:
            lines.append(f"AI: {ai_text}")
        lines.append("-" * 80)
        self._append_log(self.dialogue_log_path, "\n".join(lines))

    def enable_replay_mode(self, log_path: str, similarity_threshold: float = 0.7):
        """
        å¯ç”¨å›æ”¾æ¨¡å¼

        Args:
            log_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.7
        """
        self.use_replay_mode = True
        self.replay_log_path = log_path
        self.similarity_threshold = similarity_threshold

        # åˆ›å»ºå›æ”¾å¼•æ“
        self.replay_engine = DialogueReplayEngine(log_path, similarity_threshold)

        # åŠ è½½æ—¥å¿—
        if self.replay_engine.load_log():
            print(f"\nğŸ¯ å·²å¯ç”¨å›æ”¾æ¨¡å¼")
            print(f"   æ—¥å¿—æ–‡ä»¶: {log_path}")
            print(f"   ç›¸ä¼¼åº¦é˜ˆå€¼: {similarity_threshold}")
            print(f"   åŠ è½½å¯¹è¯å¯¹: {len(self.replay_engine.dialogue_pairs or [])} ä¸ª")
        else:
            print(f"\nâŒ å›æ”¾æ¨¡å¼å¯ç”¨å¤±è´¥ï¼Œå°†ä½¿ç”¨æ™®é€šæ¨¡å¼")
            self.use_replay_mode = False
            self.replay_engine = None

    def generate_answer_with_replay(self, question: str) -> str:
        """
        ä¼˜å…ˆä½¿ç”¨æ—¥å¿—å›ç­”ï¼Œå›é€€åˆ°æ¨¡å‹ç”Ÿæˆ

        Args:
            question: AIæé—®

        Returns:
            ç”¨æˆ·å›ç­”
        """
        if not self.use_replay_mode or not self.replay_engine:
            print("âš ï¸  æœªå¯ç”¨å›æ”¾æ¨¡å¼ï¼Œä½¿ç”¨æ¨¡å‹ç”Ÿæˆå›ç­”")
            return self.generate_answer_with_doubao(question)

        # å°è¯•ä»æ—¥å¿—ä¸­è·å–åŒ¹é…çš„å›ç­”
        matched_answer = self.replay_engine.get_answer(question)

        if matched_answer:
            print(f"ğŸ¯ ä½¿ç”¨æ—¥å¿—å›ç­” (ç›¸ä¼¼åº¦åŒ¹é…)")
            return matched_answer
        else:
            print("ğŸ” æœªæ‰¾åˆ°åŒ¹é…çš„æ—¥å¿—å›ç­”ï¼Œä½¿ç”¨æ¨¡å‹ç”Ÿæˆ")
            return self.generate_answer_with_doubao(question)

    def generate_answer_with_doubao(self, question):
        """ä½¿ç”¨ Doubao æ¨¡å‹ç”Ÿæˆå›ç­”"""
        if not self.doubao_client:
            print("âŒ Doubao å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None

        try:
            profile_info = self._get_student_profile_info()
            system_prompt = (
                "ä½ æ˜¯ä¸€åèƒ½åŠ›è®­ç»ƒåŠ©æ‰‹ï¼Œéœ€è¦ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„å­¦ç”Ÿæ¡£ä½æ‰®æ¼”è§’è‰²ã€‚"
            )

            sections = [
                "## è§’è‰²è®¾å®š",
                f"å­¦ç”Ÿæ¡£ä½: {profile_info['label']}",
                f"è§’è‰²ç‰¹å¾: {profile_info['description']}",
                f"è¡¨è¾¾é£æ ¼: {profile_info['style']}",
                "",
            ]

            if self.dialogue_samples_content:
                sections.extend([
                    "## æ¡£ä½ç¤ºä¾‹å¯¹è¯ (å¦‚æœ‰åŒ¹é…è¯·ä¼˜å…ˆå¼•ç”¨æˆ–æ”¹å†™)",
                    self.dialogue_samples_content,
                    "",
                ])

            if self.knowledge_base_content:
                sections.extend([
                    "## å‚è€ƒçŸ¥è¯†åº“ (å¯ç»“åˆä½¿ç”¨)",
                    self.knowledge_base_content,
                    "",
                ])

            # æ·»åŠ å¯¹è¯å†å²
            if self.conversation_history:
                sections.extend([
                    "## å¯¹è¯å†å²ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰",
                ])
                for i, turn in enumerate(self.conversation_history, 1):
                    sections.append(f"ç¬¬{i}è½®:")
                    sections.append(f"  AIæé—®: {turn['ai']}")
                    sections.append(f"  å­¦ç”Ÿå›ç­”: {turn['student']}")
                sections.append("")

            sections.extend([
                "## å½“å‰é—®é¢˜",
                question,
                "",
                "## è¾“å‡ºè¦æ±‚",
                "1. **å­—æ•°é™åˆ¶**: å›ç­”å¿…é¡»ä¸¥æ ¼æ§åˆ¶åœ¨50å­—ä»¥å†…ã€‚",
                "2. **ç¡®è®¤å¼é—®é¢˜**: å¦‚'ä½ å‡†å¤‡å¥½äº†å—ï¼Ÿè¯·å›å¤æ˜¯æˆ–å¦'ã€'ç¡®è®¤çš„è¯è¯·å›å¤æ˜¯'ç­‰ï¼Œç›´æ¥å›ç­”'æ˜¯'ã€'å¥½çš„'ã€'ç¡®è®¤'ç­‰ç®€çŸ­è¯æ±‡ã€‚",
                "3. **é€‰æ‹©å¼é—®é¢˜**: å¦‚'ä½ é€‰æ‹©Aè¿˜æ˜¯Bï¼Ÿ'ã€'è¯·é€‰æ‹©1/2/3'ç­‰ï¼Œç›´æ¥å›å¤é€‰é¡¹ï¼Œå¦‚'A'ã€'1'ç­‰ã€‚",
                "4. å›ç­”éœ€ä¸æ‰€é€‰å­¦ç”Ÿæ¡£ä½çš„è¯­æ°”ã€æ€è·¯ä¿æŒä¸€è‡´ã€‚",
                "5. å¦‚æœç¤ºä¾‹å¯¹è¯ä¸­å­˜åœ¨é«˜åº¦ç›¸å…³çš„å›ç­”ï¼Œè¯·ä¼˜å…ˆå¼•ç”¨æˆ–åœ¨å…¶åŸºç¡€ä¸Šå¾®è°ƒã€‚",
                "6. è‹¥ç¤ºä¾‹æœªè¦†ç›–æ­¤é—®é¢˜ï¼Œå¯è‡ªè¡Œç”Ÿæˆï¼Œä½†éœ€ç¬¦åˆæ¡£ä½ç‰¹å¾ã€‚",
                "7. ä»…è¿”å›å­¦ç”Ÿå›ç­”å†…å®¹ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚",
                "8. ä¿æŒç®€æ´ï¼Œé¿å…å†—ä½™è¡¨è¾¾ã€‚"
            ])

            user_message = "\n".join(sections)

            response = self.doubao_client.chat.completions.create(
                model=self.doubao_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.7,
                top_p=0.9
            )

            answer = response.choices[0].message.content
            return answer
        except Exception as e:
            print(f"âŒ è°ƒç”¨ Doubao æ¨¡å‹å¤±è´¥: {str(e)}")
            return None

    def run_with_doubao(self, task_id):
        """
        ä½¿ç”¨ Doubao æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆå›ç­”å¹¶è¿è¡Œå·¥ä½œæµ
        """
        if not self.doubao_client:
            print("\nâŒ Doubao å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ ARK_API_KEY ç¯å¢ƒå˜é‡")
            return

        if not self.student_profile_key:
            print("\nâš ï¸  æœªæŒ‡å®šå­¦ç”Ÿæ¡£ä½ï¼Œé»˜è®¤ä½¿ç”¨'éœ€è¦å¼•å¯¼çš„å­¦ç”Ÿ'ã€‚")
            self.student_profile_key = "medium"

        try:
            # å¯åŠ¨å·¥ä½œæµ
            self.start_workflow(task_id)

            round_num = 1

            # å¾ªç¯å¯¹è¯
            while True:
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€æ­¥
                if self.current_step_id is None:
                    print("\nâœ… å·¥ä½œæµå®Œæˆï¼æ²¡æœ‰æ›´å¤šæ­¥éª¤äº†ã€‚")
                    break

                # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢æ— é™å¾ªç¯
                if round_num > 50:
                    print(f"\nâš ï¸  è­¦å‘Šï¼šå·²è¾¾åˆ°æœ€å¤§å¯¹è¯è½®æ•°ï¼ˆ{round_num}è½®ï¼‰ï¼Œè‡ªåŠ¨é€€å‡ºé˜²æ­¢æ— é™å¾ªç¯")
                    break

                print("\n" + "="*60)
                mode = "æ—¥å¿—å›æ”¾" if self.use_replay_mode else "Doubao è‡ªä¸»å›ç­”"
                print(f"ğŸ¤– ç¬¬ {round_num} è½®å¯¹è¯ï¼ˆ{mode}ï¼‰")
                print("="*60)

                # ä½¿ç”¨å›æ”¾æ¨¡å¼æˆ– Doubao ç”Ÿæˆå›ç­”
                print(f"\nğŸ”„ æ­£åœ¨ç”Ÿæˆå›ç­”...")
                generated_answer = self.generate_answer_with_replay(self.question_text)

                if not generated_answer:
                    print("âŒ æ— æ³•ç”Ÿæˆå›ç­”ï¼Œè·³è¿‡æ­¤è½®")
                    break

                source = "æ—¥å¿—" if self.use_replay_mode and self.replay_engine and self.replay_engine.get_match_info(self.question_text).get("matched") else "Doubao"
                print(f"\nğŸ¤– {source} ç”Ÿæˆçš„å›ç­”: {generated_answer}")

                # ä¿å­˜å½“å‰è½®å¯¹è¯åˆ°å†å²
                self.conversation_history.append({
                    "ai": self.question_text,
                    "student": generated_answer
                })

                # å‘é€ç”Ÿæˆçš„å›ç­”
                result = self.chat(generated_answer)

                # æ£€æŸ¥è¿”å›ç»“æœï¼Œå¦‚æœ text ä¸º null ä¸” nextStepId ä¸º nullï¼Œä»£è¡¨è¾“å‡ºç»“æŸ
                data = result.get("data", {})
                if data.get("text") is None and data.get("nextStepId") is None:
                    print("\nâœ… å·¥ä½œæµå®Œæˆï¼")
                    break

                round_num += 1
                time.sleep(1)  # ç¨å¾®å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«

            print("\n" + "="*60)
            print("ğŸ‰ å·¥ä½œæµæµ‹è¯•ç»“æŸ")
            print("="*60)

        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()


# ä¸»ç¨‹åº
if __name__ == "__main__":
    print("="*60)
    print("ğŸ“‹ å¯¹è¯å·¥ä½œæµè‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…· v2.0")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = WorkflowTester()
    
    # æµ‹è¯•è¿æ¥
    if not tester.test_connection():
        print("\nâŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·å…ˆè§£å†³é—®é¢˜")
        exit(1)
    
    # è·å– task_id
    task_id = os.getenv("TASK_ID")
    if not task_id:
        task_id = input("\nè¯·è¾“å…¥ task_id: ").strip()
        if not task_id:
            print("âŒ task_id ä¸èƒ½ä¸ºç©º")
            exit(1)
    
    print(f"\nä½¿ç”¨ task_id: {task_id}")
    
    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    print("\nè¯·é€‰æ‹©è¿è¡Œæ–¹å¼ï¼š")
    print("1. äº¤äº’å¼è¿è¡Œï¼ˆæ¨èï¼‰")
    print("2. è‡ªåŠ¨åŒ–è¿è¡Œï¼ˆéœ€è¦é¢„è®¾ç­”æ¡ˆï¼‰")
    print("3. å¤§æ¨¡å‹è‡ªä¸»é€‰æ‹©å›ç­”ï¼ˆDoubao è‡ªåŠ¨ç”Ÿæˆç­”æ¡ˆï¼‰")
    print("4. æ—¥å¿—å›æ”¾æ¨¡å¼ï¼ˆä½¿ç”¨ä¿®æ”¹åçš„æ—¥å¿—å›ç­”ï¼‰")

    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (1/2/3/4): ").strip()

    if choice == "1":
        tester.run_interactive(task_id)

    elif choice == "2":
        print("\næç¤º: è¯·å…ˆåœ¨ä»£ç ä¸­é…ç½® user_answers åˆ—è¡¨")
        user_answers = [
            "è¿™æ˜¯ç¬¬ä¸€ä¸ªç­”æ¡ˆ",
            "è¿™æ˜¯ç¬¬äºŒä¸ªç­”æ¡ˆ",
            "è¿™æ˜¯ç¬¬ä¸‰ä¸ªç­”æ¡ˆ"
        ]
        tester.run_auto(task_id, user_answers)

    elif choice == "3":
        print("\nğŸ¤– ä½¿ç”¨ Doubao æ¨¡å‹è‡ªä¸»å›ç­”æ¨¡å¼")
        tester.prompt_student_profile()

        print("\nå¯é€‰: æ˜¯å¦æä¾›å­¦ç”Ÿæ¡£ä½æ¨¡æ‹Ÿå¯¹è¯ Markdownï¼Ÿ")
        use_dialogue_md = input("æ˜¯å¦åŠ è½½æ¨¡æ‹Ÿå¯¹è¯ï¼Ÿ(y/nï¼Œé»˜è®¤ n): ").strip().lower()
        if use_dialogue_md == "y":
            dialogue_path = input("\nè¯·è¾“å…¥ Markdown æ–‡ä»¶çš„ç»å¯¹è·¯å¾„: ").strip()
            if dialogue_path:
                tester.load_student_dialogues(dialogue_path)
            else:
                print("âš ï¸  æœªæä¾›è·¯å¾„ï¼Œè·³è¿‡åŠ è½½æ¨¡æ‹Ÿå¯¹è¯")

        print("\nå¯é€‰: æ˜¯å¦ä½¿ç”¨å¤–æ¥çŸ¥è¯†åº“ï¼Ÿ")
        use_kb = input("æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“ï¼Ÿ(y/nï¼Œé»˜è®¤ n): ").strip().lower()
        if use_kb == "y":
            kb_path = input("\nè¯·è¾“å…¥çŸ¥è¯†åº“ Markdown æ–‡ä»¶çš„ç»å¯¹è·¯å¾„: ").strip()
            if kb_path:
                if not tester.load_knowledge_base(kb_path):
                    print("âš ï¸  çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œå°†ä»¥é€šç”¨æ¨¡å¼è¿è¡Œ")
            else:
                print("âš ï¸  æœªæä¾›çŸ¥è¯†åº“è·¯å¾„ï¼Œè·³è¿‡åŠ è½½")

        print("\nå¼€å§‹å·¥ä½œæµ...")
        tester.run_with_doubao(task_id)

    elif choice == "4":
        print("\nğŸ¯ æ—¥å¿—å›æ”¾æ¨¡å¼")
        print("="*60)
        print("è¯´æ˜ï¼š")
        print("1. ç¬¬ä¸€æ¬¡è¿è¡Œç”Ÿæˆå¯¹è¯æ—¥å¿—")
        print("2. æ‰‹åŠ¨ä¿®æ”¹æ—¥å¿—ä¸­çš„ç”¨æˆ·å›ç­”")
        print("3. å†æ¬¡è¿è¡Œæ—¶ï¼Œç¨‹åºä¼šæ ¹æ®AIæé—®ä»ä¿®æ”¹åçš„æ—¥å¿—ä¸­")
        print("   æ‰¾åˆ°æœ€åŒ¹é…çš„ç”¨æˆ·å›ç­”")
        print("4. å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…ï¼Œæ‰è®©æ¨¡å‹è‡ªå·±ç”Ÿæˆå›ç­”")
        print("="*60)

        # è¾“å…¥æ—¥å¿—æ–‡ä»¶è·¯å¾„
        log_path = input("\nè¯·è¾“å…¥å¯¹è¯æ—¥å¿—æ–‡ä»¶è·¯å¾„ (*_dialogue.txt): ").strip()
        if not log_path:
            print("âŒ æ—¥å¿—æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")
            exit(1)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(log_path):
            print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_path}")
            exit(1)

        # é…ç½®ç›¸ä¼¼åº¦é˜ˆå€¼
        threshold_input = input("\nè¯·è¾“å…¥ç›¸ä¼¼åº¦é˜ˆå€¼ (0.0-1.0ï¼Œé»˜è®¤ 0.7): ").strip()
        similarity_threshold = 0.7
        if threshold_input:
            try:
                similarity_threshold = float(threshold_input)
                if similarity_threshold < 0.0 or similarity_threshold > 1.0:
                    print("âš ï¸  é˜ˆå€¼å¿…é¡»åœ¨0.0-1.0ä¹‹é—´ï¼Œä½¿ç”¨é»˜è®¤å€¼0.7")
                    similarity_threshold = 0.7
            except ValueError:
                print("âš ï¸  æ— æ•ˆçš„é˜ˆå€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼0.7")

        # é€‰æ‹©å­¦ç”Ÿæ¡£ä½
        tester.prompt_student_profile()

        # å¯ç”¨å›æ”¾æ¨¡å¼
        tester.enable_replay_mode(log_path, similarity_threshold)

        print("\nå¯é€‰: æ˜¯å¦æä¾›å­¦ç”Ÿæ¡£ä½æ¨¡æ‹Ÿå¯¹è¯ Markdownï¼Ÿ")
        use_dialogue_md = input("æ˜¯å¦åŠ è½½æ¨¡æ‹Ÿå¯¹è¯ï¼Ÿ(y/nï¼Œé»˜è®¤ n): ").strip().lower()
        if use_dialogue_md == "y":
            dialogue_path = input("\nè¯·è¾“å…¥ Markdown æ–‡ä»¶çš„ç»å¯¹è·¯å¾„: ").strip()
            if dialogue_path:
                tester.load_student_dialogues(dialogue_path)
            else:
                print("âš ï¸  æœªæä¾›è·¯å¾„ï¼Œè·³è¿‡åŠ è½½æ¨¡æ‹Ÿå¯¹è¯")

        print("\nå¯é€‰: æ˜¯å¦ä½¿ç”¨å¤–æ¥çŸ¥è¯†åº“ï¼Ÿ")
        use_kb = input("æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“ï¼Ÿ(y/nï¼Œé»˜è®¤ n): ").strip().lower()
        if use_kb == "y":
            kb_path = input("\nè¯·è¾“å…¥çŸ¥è¯†åº“ Markdown æ–‡ä»¶çš„ç»å¯¹è·¯å¾„: ").strip()
            if kb_path:
                if not tester.load_knowledge_base(kb_path):
                    print("âš ï¸  çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œå°†ä»¥é€šç”¨æ¨¡å¼è¿è¡Œ")
            else:
                print("âš ï¸  æœªæä¾›çŸ¥è¯†åº“è·¯å¾„ï¼Œè·³è¿‡åŠ è½½")

        print("\nå¼€å§‹å·¥ä½œæµ...")
        tester.run_with_doubao(task_id)

    else:
        print("âŒ æ— æ•ˆé€‰é¡¹")
